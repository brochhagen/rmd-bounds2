\documentclass[12pt,a4paper]{article}
\usepackage{tikz}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{nicefrac}
\usepackage{multirow}
\usepackage{fixltx2e}
\usepackage[round]{natbib}
\bibpunct[:]{(}{)}{,}{a}{}{;}

	\newcommand{\tuple}[1]{\ensuremath{\left\langle #1 \right\rangle}} 
	\newcommand{\citeposs}[2][]{\citeauthor{#2}'s (\citeyear[#1]{#2})}
	\newcommand{\citeposss}[2][]{\citeauthor{#2}' (\citeyear[#1]{#2})}
	\newcommand{\hl}[1]{\textcolor[rgb]{.8,.33,.0}{#1}}% prints in orange

\usepackage{mathcomp}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage[fleqn]{amsmath}

\usepackage{mdframed}

\begin{document}

\newcounter{reviewerCounter}
\newcounter{reviewerCommentCounter}[reviewerCounter]
	\date{}

\title{\Large Co-evolution of lexical meaning \& pragmatic use\\ {\bf Revision Cover letter}}

	\maketitle
\normalsize

We would like to thank the reviewers for their helpful comments and suggestions. They are very welcome and have certainly helped improve the manuscript. 

We have taken care to improve the exposition of the model; to clarify the  motivations underlying the modeling choices we make in the case study, and to make more precise and explicit how the components of the model lead to the results they do. In what follows we address the reviewers' main comments and questions one by one, with pointers to respective changes effected on the manuscript. 


\vspace{1cm}

%

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCounter} %increase counter
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it co-evolution})]
the co-evolutionary dynamic mentioned in the title could be better justified [...] In co-evolutionary dynamics, the evolution of one factor (here, the lexicon) should have an impact on the evolution of another (here, pragmatic strategy), and vice versa; the paper does not show evolutionary dynamics (change over time) for either of these factors, not does it show how evolution of a single factor favours the evolution of the other. [...] Please justify your characterization of the process modeled as co-evolution or change to adaptation.

\end{mdframed}

This is an important point that we now stress and highlight more throughout the paper. In particular the material surrounding Figure $2$ and $3$ in the new Section~2.4 illustrates how one factor has an impact on the evolution of the other. In a nutshell: a pragmatic strategy (level-$1$ reasoning) favors the evolution of underspecified semantics of the target kind ($L_{\text{lack}}$) as it allows for the maintenance of simpler lexical representations that are easier to learn without functional disadvantages otherwise incurred in communication (e.g., by level-$0$ reasoners). In the other direction, underspecified semantics of the target kind also favors the evolution of a pragmatic disposition to act on them. When paired with other semantics, pragmatic refinement can instead be (close to a) neutral trait (e.g., $L_{\text{bound}}$ paired with high $\lambda$) or it can even lead to  functional disadvantages when compared with level-$0$ reasoning (e.g., $L_{\text{bound}}$ with low $\lambda$). In this way both features benefit from each other.

%

\vspace{.75cm}
\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it modeling choices})]
the mapping between the model and the example of choice (scalar implicatures) could be better motivated
\end{mdframed}

As we discuss in Section~1, our case study focuses on scalar implicatures because they are well-studied systematic pragmatic inferences that have received much attention, both theoretically and experimentally. This makes them suitable candidates for the study of the evolution of regular pragmatic inferences; past research can guide our modeling choices and aid in evaluating our application to the study of these inferences. This ties in with our particular choices to model the pragmatic use of scalar expressions. As we now make more explicit in \S 2.3.1, these draw from a growing game-theoretic and Bayesian tradition \citep[e.g.,][]{franke:2009,FrankeJager2015:Probabilistic-p,GoodmanFrank2016:Pragmatic-Langu}. 

%
\vspace{.75cm}
\noindent\rule{\textwidth}{1pt}
\vspace{.1cm}

\stepcounter{reviewerCommentCounter} %increase counter
\noindent Reviewer \thereviewerCounter~asks for a clearer description of the model. As noted earlier, we have taken care to make the exposition more accessible and to guide the reader more through the technical details of Section 2. In particular, the newly added Section 2.4 should help readers unravel the model. We used the following questions from Reviewer 1, briefly answered below, to guide the changes made in Section~2.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
How is generation transmission implemented?
\end{mdframed}
As it is unlikely that lexical representations and/or pragmatic reasoning are inherited genetically, we model the transmission of linguistic knowledge across generations as  iterated Bayesian learning. Technical details and motivations are given in \S 2.3.3.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Do agents in a population die little by little and are replaced by new agents? Or all at once?
\end{mdframed}
As now made more explicit in \S2.2, steps of the discrete-time replicator mutator dynamic correspond to generational turn-overs of the entire population (definitions (1) and (2)). That is to say, all agents die at once, being replaced by the following generation in a single swoop. 

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Do the models consider just a single teacher and a single learner at a time (I don't think this is the case, since the results refer speak of ``majority type, i.e., the type with the highest proportion in the final population'')?
\end{mdframed}
The parenthetical remark is correct. The amount of teachers of a given type is proportional to the frequency of this type in the population after the replicator step. The population is infinite so there are technically infinite learners/teachers. This was implicit in the definitions of the replicator mutator dynamic in (1) and (2), and is now explicitly stated in Section~2.2 in the prose that motivates and explicates these definitions.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
 How many agents were there per population? And per generation?
\end{mdframed}
The prose surrounding definitions (1) and (2) in Section 2.2 now makes explicit that the population is infinite. This allows us to track change that does not depend on varying population sizes nor their growth rate. This is why we speak of proportions of a type in a population, rather than of there being a particular number of agents of a type. 

\vspace{.5cm}
  \begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Within one run of the model, do all agents in a population have the same lambda, l and k? If so, please this homogeneous population, and discuss the possible consequences of variation in the population in these parameters.
\end{mdframed}
While our model is compatible with the assumption that every agent comes with her own parameter values, the reviewer is correct in pointing out that we assume they all to have the same values (explicit in \S3.2). Variation across agents would mean having many more types: one for each combination of a possible lexicon, pragmatic strategy, $\lambda$-, $l$- and $k$-value. This would allow us to trace the evolutionary trajectory of not only lexica and pragmatic strategies, which is our goal here, but of all these factors combined. As mentioned in Section~$4$, this would be interesting future research.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Does the model assume that learners observe not only the behaviour (the message, e.g. agent A hearing agent B say: "I own some of JC's albums") but also the true state of the world (i.e. agent A also knows whether agent B owns all or some-but-not-all albums)? Or do they get feedback on their communicative success? In other words, how do they learn the correct state-message mappings that form the lexicon? 
\end{mdframed}
Learners witness sequences of data $d$. Such a sequence is composed of message-state pairings. In other words, learners do witness the true state of the world (Section~2.3.3, {\em learnability}).

The probability of the learner receiving learning input $d$ depends only on the likelihood of the teacher producing it. This is determined by the teacher's production probabilities; the speaker behavior of her type. Communicative success accordingly does not come into play, only speaker behavior. It would certainly be possible to let learners witness proficient users communicate and to have them infer types from such interactions instead. However, we wanted to keep our assumptions close to the well-studied assumptions standardly made in the iterated (Bayesian) learning tradition. Iterated learning only considers production, rather than production and comprehension. Details on how learners infer types are given in Section~2.3.3.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
How exactly are pragmatic strategies inherited/inferred by learners?    I think all of this may be in the formulas, but it would be useful if it was expressed in prose too.
\end{mdframed}
In short, a type is a combination of a lexicon and a disposition to act on it. Together, both ingredients define an agent's linguistic behavior. A learner faced with input $d$ (see above) calculates $P(\tau \mid d)$, the probability that a type $\tau$ produced input $d$. Crucially, neither linguistic strategies nor lexical meanings are directly observable, so they can only be faithfully recovered inasmuch as the {\em overt} behavior evidenced by a type -- the data it produces -- is (in tendency) attributable to only one, {\em covert}, pairing of a lexicon and a linguistic strategy.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Could you express in prose how literal and pragmatic use work in practice? I am not sure I understand why you call the strategies `pragmatic', given that pragmatics depends on the context, and there is no context here. I would like to see the use of the term `pragmatic' justified further in the paper.
\end{mdframed}
We follow the Gricean tradition of viewing pragmatic inference as effected by mutual reasoning about rational language use (Section~1). This may involve the recruitment of contextual information, as the reviewer notes, but can also involve pragmatic enrichments that result purely from reasoning about linguistic alternatives (``why did the speaker say {\em some} instead of {\em all}''). It is in the latter sense that reasoning beyond level $0$ is pragmatic (see \S2.3.1). Classically, theoretical analyses of scalar implicatures have put their emphasis on reasoning about linguistic choice rather than on contextual information \citep[e.g.,][]{horn:1972,gazdar:1979, franke:2009, GoodmanStuhlmuller2013:Knowledge-and-I}. We chose to do the same here.

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
I thought $\lambda$ was the parameter that modeled communication, so it should not be present in the iterated-learning-without-communication models; why is $\lambda$ set to 20 here, and why discuss lower levels of lambda? 
\end{mdframed}
This parameter regulates the linguistic production behavior of types, i.e., speaker behavior. Speaker behavior is relevant both for communication with hearers as well as for the learning input that a teacher produces. When considering only iterated Bayesian learning $\lambda$ accordingly also plays a role because different $\lambda$ values yield different likelihoods of producing particular data (see above and Section~2.3.3). 

\vspace{.5cm}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Also [in the Subsection {\em learnability only}], why isn't the proportion of Lall highest, given that it has the lowest complexity (highest prior)?
\end{mdframed}
%
Due to their stochastic speaker behavior, the data produced by $L_{\text{all}}$-teachers tends to be compatible with the behavior of many other types. Intuitively, the data such teachers produce are all over the place and do not do a good job in setting them apart from other types. Consequently, even if the prior favors $L_{\text{all}}$, this type is not transmitted very faithfully; learners reason that the input they get from $L_{\text{all}}$-teachers could also come from other types and may adopt those instead. If there are types that are transmitted more faithfully, the population will, over time, transition to these types rather than to $L_{\text{all}}$. As we put it in Section~4, iterated learning does not necessarily promote the {\em a priori} more likely type, but tends to promote a type $t$ based on a gradient of how many other types might likely mutate into $t$, so to speak. We stress this in Section~3.2.2 and Section~4.

\vspace{1cm}
\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it LOT \& model relation})]
%
This model rests heavily on the assumption that the representation or meaning of an expression is a logical formula like those in Table 2, and that these formulas yield a complexity hierarchy.  This may be valid for scalar implicature, as you argue, but how realistic is it cognitively for other linguistic structures or for other socially learned items? Should we assume the non-parsimonious view that there are different complexity measures for different linguistic structures? It would be nice to see another linguistic or cultural example that could be fitted with this model.
%
\end{mdframed}

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
Learnability [...] is operationalized as the complexity of the minimal logical formula for each state. Another possible measure of the difficulty/ease of learning would be comparing the regularity/systematicity of the lexicon types given in 3.1.1 (measured e.g. as mutual information (Cornish, Tamariz, Kirby 2009; using the mantel test, Kirby, Tamariz, Cornish, Smith 2015). Yet another approach to complexity would be to assume that the meanings are mutually exclusive categories without internal structure, or to assume a preference or mutual exclusivity. In these cases, I expect L-bound (competitor), to be easier to learn than L-lack (target). Please justify your choice of learnability measure in the face of these alternatives.
\end{mdframed}

We do not believe that, ultimately, the non-parsimonious view that there are different complexity measures for different structures should be assumed. However, with previous work in the iterated learning tradition, we do assume that (i) inductive learning biases can play a role in shaping culturally transmitted knowledge and that, as the reviewer notes, (ii) biases can be of manifold nature; another well-studied example being the mutual exclusivity bias, which could be expected to work against targets and in favor of competitors.

At present, it is impossible to disentangle the complex interaction of multiple biases. We therefore focus on the effects of a single plausible contributing factor to a preference of target lexica over competitors: a well-motivated bias favoring simplicity \citep{feldman:2000,chater+vitanyi:2003, piantadosi+etal:2012a,kirby+etal:2015,piantadosi+etal:underreview}. By assumption, this translates to a preference not to lexicalize linguistic material over lexicalizing it; simpler formulae over complex ones. As mentioned in Section 3.1.2, the complexity measure that the prior is based on is just a convenient operationalization of this particular hypothesis. 

We should stress that, just as models of iterated learning make different predictions under the assumption of different inductive biases, so does our model. The assumption and operationalization of a particular bias should, of course, always be seen critically (Section 4). 

%

\vspace{0.5cm}
\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it transmission fidelity})]
%
What is your measure of fidelity/infidelity? Is it just 0 if the teacher and learner are of a different type and 1 if they are of the same? Could you have a more graded measure of fidelity, e.g. taking into account if two types are of the same 'kind' or not? 
\end{mdframed}
%
We understand transmission fidelity as the probability of acquiring type $i$ when learning from type $i$ (Section~2.3.3). This is the value of a cell in the learning matrix $Q$. In this case, $Q_{ii}$. As discussed in Section~2.2, if $Q_{ii} = 1$ then $i$ is always acquired when learning from type $i$. On the other extreme, $Q_{ii} = 0$ means that $i$ is never acquired from $i$. $Q$ is a stochastic matrix and we we usually see neither extreme but rather, as suggested by the reviewer, a graded notion of transmission fidelity (Section~2.2). The details on how $Q$ is computed are given in Section 2.3.3. We have expanded this section to make these details clearer in the prose.
%

\vspace{0.5cm}




\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCounter} %increase counter
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it Interpretation of results})]
%
The results are interesting, though somewhat difficult to interpret. First, pragmatic language use does not evolve in the absence of learnability pressures, due to its slightly lower fitness. Second, pragmatic language use can arise from learnability pressures alone, though only for sufficiently ``rational'' learners. Third, pragmatic language use can evolve given both fitness and learnability pressures, though only if both learners and language speakers are both sufficiently optimal. The first two results are fairly straightforward, but the third (which is the most important in the paper) is more puzzling. Why do learnability pressures not have the same effect in the joint learnability/fitness model, as they do in the lesioned model? Why is high speaker optimality necessary for scalar implicatures to evolve, when it does not have this effect in the fitness-only model?
\end{mdframed}

We have thoroughly revised the manuscript to make the contrast between these three predictions clearer (see Section~3.2, particularly 3.2.3; but also Section~2.4, which illustrates how the dynamics behave in a smaller type space). These questions tie in with Reviewer $1$'s request for a clearer exposition and the explanation of why we speak of co-evolution in this case (reviewer 1, comment 1). In a nutshell, pressure for learnability alone does not put the types in a population in competition. Instead, the population comes to be inhabited by types that are recovered from learning input of replicated types more often -- of which there might be many (e.g., all variants of a kind are equally learnable; if there are many variants of a type that is, in tendency, acquired more often, then the population will stay polymorphic). What fitness-relative selection adds to this process is the competition that learnability alone lacks, independent of the type space we look at. Now, in the case of our type space we have a slight (modulo $\lambda$) communicative disadvantage for targets relative to competitors, for instance. However, the fact that targets are inferred more more often by na\"ive learners, also from those that learn from competitors, leads (i) to the gradual existence of less competitors, counteracting this functional disadvantage, as well as (ii) to the existence of only one variant of a kind (contra what we get in the {\em learning alone} condition).
%

\vspace{0.5cm}

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it Model predictions})]
%
I agree with its claim that the results are non-trivial; it is not clear a priori that there should exist any regimes where learnability and fitness pressures balance in order to produce scalar implicatures. The paper does not, however, address why the pressures do balance in this case. Are there general theorems (from previous work) about the replicator mutator dynamic that could be brought to bear here? How do learnability and fitness pressures trade-off in general? Is there anything more general that can be said about conditions under which pragmatic language use will evolve? Does the current example generalize to other cases of pragmatic language use? The paper does not need to answer these questions in an exhaustive manner, but greater scientific understanding of the model is desired.
\end{mdframed}

As noted above, we have expanded our analysis of the model and put much more emphasis on how the components that feed it play a role in driving particular evolutionary outcomes. See, in particular, Section 2.4, Section 3.2, and Section 4.
%

\vspace{0.5cm}

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it co-evolution and pragmatic maintenance})]
%
It makes sense for agents to acquire their grammar/lexicon by learning, as these are social conventions. I believe, however, that the paper also assumes that an agent's pragmatic type (i.e. whether they are literal or pragmatic speakers) is also determined by learning. This is more difficult to interpret. It is reasonable for an agent to learn whether the other agents in a population are behaving pragmatically. Even if the other agents are not behaving pragmatically, however, it will be rational for the learner to behave pragmatically. This is a property of the recursive definition of the pragmatics model. The pragmatic speaker is defined so as to select utterances that will be correctly interpreted by the literal listener. If an agent learns that their interlocutors are all literal agents, then it would be rational for them to pragmatically reason about these literal agents. It is therefore not clear why the agents should, as currently proposed, copy the inferred pragmatic type of their interlocutor.
\end{mdframed}

It is not necessarily true that it will always be advantageous for agents to behave pragmatically (see the end of Section~2.3.1 but also the discussion surrounding Figure~3a).  The main thing to note is that a pragmatic level-$1$ hearer using lexicon $L_{\text{bound}}$ will reason about the behavior of a {\em soft-maximizing} level-$0$ speaker of $L_{\text{bound}}$. The lower $\lambda$, the more the stochasticity percolates from the level-$0$ speaker to level-$1$ pragmatic interpretation. By contrast, literal level-$0$ hearers of $L_{\text{bound}}$ have a one-to-one form-meaning mapping from the get go. Put differently, pragmatic reasoning can actually encumber some hearers, depending on their lexicon. Particularly if $\lambda$ is low.


%
\vspace{0.5cm}

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it agent simplicity})]
%
The paper assumes that the speaker (and listener) know the type of the player that they're interacting with. This does not seem like a natural assumption. Unless the speaker has repeated interactions with the listener (which is not assumed in the paper), the pragmatic type of the other agent is a latent property. One could imagine the speaker calculating expected utility with respect to the distribution on players that they expect (and speakers of different types choosing different strategies against this distribution). 

%
\end{mdframed}

As we now clarify in Section~2.3.1 and stress a couple of times throughout the article, we assume very little sophistication from our agents. In particular, they do not know the type of the player that the are playing against. They simply behave according to their subjective point of view in a boundedly rational fashion. For example, the linguistic choices of a level-$1$ speaker of lexicon $L_{\text{some}}$ do not change depending on whom she interacts with. They are always defined as (boundedly) rational choice relative to the interpretative behavior of a level-$0$ user of $L_{\text{some}}$ (see definitions (3) --(6) in \S2.3.1).
%

\vspace{0.5cm}

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it posterior type sampling})]
%
The learner in this model always selects a particular grammar/pragmatic type. An alternative would be for them to maintain uncertainty about the type (which is optimal behavior from a Bayesian perspective). I suspect that this model is intractable (or at least much less manageable) than the proposed one, but it would be worth noting that this is a substantive choice point in the model.
\end{mdframed}
We now highlight that this is a design choice and that there are alternatives in Section~2.3.3.

\vspace{0.5cm}

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it definitions in rational language use})]
%
The current pragmatic model is somewhat non-standard. In particular, neither the literal nor pragmatic speakers in Equations 3-6 use an information-theoretic utility function, as is standard in the literature. One consequence of this is that there is now an asymmetry between the literal speaker and listener: the literal listener never interprets utterances in a manner inconsistent with their literal meanings, while the literal speaker will sometimes use utterances in a non-literal way. I do not think this needs to be changed -- the current utility function is perfectly sensible -- but this is worth noting in the paper. It would also be desirable to know (possibly in future work) whether the modeling results are robust to switching to information-theoretic utility functions.

%
\end{mdframed}
\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25]
%
A related issue is in the fitness definition in Section 2.3.2. If one adopts the alternate utility function above for the agents' behavior, then it would be natural to have fitness scale in a logarithmic manner as well. In this case, the information-theoretic utility function would have the following interpretation: the fitness of a language is determined by how well it allows speakers to communicate their beliefs, rather than how often it leads the listener to make the correct guess about the world. Similar robustness questions apply here as above.

%
\end{mdframed}
There are many alternatives when it comes to definitions of rational language use. The definitions that draw more strongly from a game-theoretic tradition standardly do not make use of an information-theoretic utility function (see \citealt{qing+franke:2015} for an overview and discussion up to $2015$). As noted in our answer to Reviewer 1's comment 2, we have taken care to highlight that our choices draw from this literature and to mention that there are other alternatives in the same spirit. 

%

\vspace{0.5cm}

\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it Learnability})]
%
Throughout, the paper mostly equates the learnability of a grammar with its complexity/prior probability. In general, however, the relationship may be more complex. Certain grammars may require less data than others to be statistically identified. This is probably not an issue in the current case study, given the simplicity of the grammars and the large amount of data relative to grammar size, but this is likely to be an issue in other cases.

%
\end{mdframed}

This is an important point. We agree that some fragments of our previous manuscript could lead to confusion, e.g., as to why $L_{\text{all}}$, being the {\em a priori} more likely type to be inferred, did not come out strongly even in the {\em learning only} condition. Throughout the article, we now stress more that what matters is the posterior, and put emphasis on the role of the likelihood.


%


\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCounter} %increase counter
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it expected utility})]
%
what would be the impact of assuming that fitness is not contributed equally by being successful as speaker and being successful as a perceiver?

%
\end{mdframed}

This is a standard assumption in the literature (lacking reasons to believe that there is an asymmetry in how often, on average, agents use and hear a type of expression.) In the case of scalar implicatures, we see no reason to assume such an asymmetric contribution. As for concrete impact: The main contrast that we are interested in (competition between targets and competitors) does not hinge on agents being speakers half of the time. However, e.g., the contrast between pragmatic and literal competitor types does, as they differ only in their receiver behaviors. Assuming that receiver behavior contributes differently than sender behavior would therefore modulate differences between these types.

%
\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it message amount})]
%
what motivates modelling just three messages and not just two (``some'' and ``all'') or any $n>3$? One obvious prediction: $n=2$ will lead to larger prevalence of lack types, whereas increasing $n$ beyond $3$ will do the opposite. More concretely: is there any non-trivial relative frequency of some/all that could falsify the results obtained in the paper?

%
\end{mdframed}

As now made explicit in Section~3.1, we chose three messages for illustrative purposes mainly. In particular, we wanted to inspect a type space where targets are not the most likely {\em a priori} as this may mislead readers into thinking that learnability alone, in particular the prior alone, drives the outcome. A larger type space also better allows us to showcase that multiple kinds of a type may exist and how this affects evolutionary outcomes. The reason why we did not go beyond $3$ messages is for computational tractability. Calculating $Q$, even if approximated, is expensive. The question whether increasing the type space will decrease the frequency to which we expect to see pragmatic {\em some} users is interesting. At present, we have no answer. 



\noindent\rule{\textwidth}{1pt}
\stepcounter{reviewerCommentCounter} %increase counter

\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it LOT \& complexity})]
%
The discussion on derivation costs is not very satisfying on my opinion. For instance, the condition of "simple representations being favored over more complex ones" is compatible with many more cost specifications.

%
\end{mdframed}

We have expanded this section to further motivate our choices (see also the discussion in Section~4). Relatedly, see our answer to Reviewer 1's comment 4 above.

%\noindent\rule{\textwidth}{1pt}
%\stepcounter{reviewerCommentCounter} %increase counter
%\stepcounter{reviewerCounter} %increase counter
%
%\begin{mdframed}[backgroundcolor=gray!25,linecolor=gray!25,frametitle= Reviewer \thereviewerCounter~comment \thereviewerCommentCounter \hfill ~~({\it topic of the issue})]
%%
%reviewer comment
%%
%\end{mdframed}
%
%
%and here we answer
%%
%
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{apalike}
\bibliography{./bounds-rmd}





\end{document}
